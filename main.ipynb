{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.data_processing.datasplit import split_dataset\n",
    "file_dir = {\"original_dir_path\": './data/samples',\n",
    "            \"splited_dir_path\": \"./dataset\"\n",
    "            }\n",
    "\n",
    "split_dataset(file_dir['original_dir_path'], file_dir['splited_dir_path'])\n",
    "\n",
    "hp = {\"batch_size\": 16,\n",
    "      \"max_dataset_size\": 856\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "from module.data_processing.custom_dataset import load_data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(transform, hp['batch_size'], hp['max_dataset_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.model.resnet_based import CaptchaResNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Example setup\n",
    "num_classes = len('0123456789abcdefghijklmnopqrstuvwxyz')  # Adjust as necessary\n",
    "sequence_length = 5  # Adjust based on your CAPTCHA length\n",
    "model = CaptchaResNet(num_classes, sequence_length)\n",
    "model.to(device)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming 'model' is already defined and modified for the correct output\n",
    "def train_model(num_epochs, model, train_loader, device):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Assuming labels are now [batch_size, sequence_length] with class indices\n",
    "            outputs = model(images)  # outputs should be [batch_size, sequence_length, num_classes]\n",
    "            loss = 0\n",
    "            for i in range(sequence_length):  # Loop over each character position\n",
    "                loss += criterion(outputs[:, i, :], labels[:, i])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1167\n",
      "Epoch [1/5], Loss: 0.0940\n",
      "Epoch [1/5], Loss: 0.1103\n",
      "Epoch [1/5], Loss: 0.1120\n",
      "Epoch [1/5], Loss: 0.0999\n",
      "Epoch [1/5], Loss: 0.1088\n",
      "Epoch [1/5], Loss: 0.1608\n",
      "Epoch [1/5], Loss: 0.0774\n",
      "Epoch [1/5], Loss: 0.0829\n",
      "Epoch [1/5], Loss: 0.0864\n",
      "Epoch [1/5], Loss: 0.0772\n",
      "Epoch [1/5], Loss: 0.1206\n",
      "Epoch [1/5], Loss: 0.0850\n",
      "Epoch [1/5], Loss: 0.0976\n",
      "Epoch [1/5], Loss: 0.1373\n",
      "Epoch [1/5], Loss: 0.0958\n",
      "Epoch [1/5], Loss: 0.1076\n",
      "Epoch [1/5], Loss: 0.1127\n",
      "Epoch [1/5], Loss: 0.0694\n",
      "Epoch [1/5], Loss: 0.0942\n",
      "Epoch [1/5], Loss: 0.0915\n",
      "Epoch [1/5], Loss: 0.0805\n",
      "Epoch [1/5], Loss: 0.1516\n",
      "Epoch [1/5], Loss: 0.0824\n",
      "Epoch [1/5], Loss: 0.1240\n",
      "Epoch [1/5], Loss: 0.0901\n",
      "Epoch [1/5], Loss: 0.0840\n",
      "Epoch [1/5], Loss: 0.0962\n",
      "Epoch [1/5], Loss: 0.0709\n",
      "Epoch [1/5], Loss: 0.0814\n",
      "Epoch [1/5], Loss: 0.1328\n",
      "Epoch [1/5], Loss: 0.1090\n",
      "Epoch [1/5], Loss: 0.0844\n",
      "Epoch [1/5], Loss: 0.0721\n",
      "Epoch [1/5], Loss: 0.1189\n",
      "Epoch [1/5], Loss: 0.0708\n",
      "Epoch [1/5], Loss: 0.0836\n",
      "Epoch [1/5], Loss: 0.0991\n",
      "Epoch [1/5], Loss: 0.0728\n",
      "Epoch [1/5], Loss: 0.0709\n",
      "Epoch [1/5], Loss: 0.1260\n",
      "Epoch [1/5], Loss: 0.0843\n",
      "Epoch [1/5], Loss: 0.0932\n",
      "Epoch [1/5], Loss: 0.0701\n",
      "Epoch [1/5], Loss: 0.0652\n",
      "Epoch [1/5], Loss: 0.0619\n",
      "Epoch [1/5], Loss: 0.0807\n",
      "Epoch [1/5], Loss: 0.1309\n",
      "Epoch [1/5], Loss: 0.0961\n",
      "Epoch [1/5], Loss: 0.0906\n",
      "Epoch [1/5], Loss: 0.1566\n",
      "Epoch [1/5], Loss: 0.0818\n",
      "Epoch [1/5], Loss: 0.0928\n",
      "Epoch [1/5], Loss: 0.1961\n",
      "Epoch [2/5], Loss: 0.0693\n",
      "Epoch [2/5], Loss: 0.0682\n",
      "Epoch [2/5], Loss: 0.0878\n",
      "Epoch [2/5], Loss: 0.0651\n",
      "Epoch [2/5], Loss: 0.0700\n",
      "Epoch [2/5], Loss: 0.0505\n",
      "Epoch [2/5], Loss: 0.0855\n",
      "Epoch [2/5], Loss: 0.0775\n",
      "Epoch [2/5], Loss: 0.0687\n",
      "Epoch [2/5], Loss: 0.0725\n",
      "Epoch [2/5], Loss: 0.0592\n",
      "Epoch [2/5], Loss: 0.1078\n",
      "Epoch [2/5], Loss: 0.0675\n",
      "Epoch [2/5], Loss: 0.0871\n",
      "Epoch [2/5], Loss: 0.0553\n",
      "Epoch [2/5], Loss: 0.1295\n",
      "Epoch [2/5], Loss: 0.0974\n",
      "Epoch [2/5], Loss: 0.0839\n",
      "Epoch [2/5], Loss: 0.1418\n",
      "Epoch [2/5], Loss: 0.0932\n",
      "Epoch [2/5], Loss: 0.0617\n",
      "Epoch [2/5], Loss: 0.0495\n",
      "Epoch [2/5], Loss: 0.0440\n",
      "Epoch [2/5], Loss: 0.0570\n",
      "Epoch [2/5], Loss: 0.0734\n",
      "Epoch [2/5], Loss: 0.0729\n",
      "Epoch [2/5], Loss: 0.0709\n",
      "Epoch [2/5], Loss: 0.1339\n",
      "Epoch [2/5], Loss: 0.0998\n",
      "Epoch [2/5], Loss: 0.0907\n",
      "Epoch [2/5], Loss: 0.0625\n",
      "Epoch [2/5], Loss: 0.0861\n",
      "Epoch [2/5], Loss: 0.0630\n",
      "Epoch [2/5], Loss: 0.1182\n",
      "Epoch [2/5], Loss: 0.0819\n",
      "Epoch [2/5], Loss: 0.0759\n",
      "Epoch [2/5], Loss: 0.0710\n",
      "Epoch [2/5], Loss: 0.0922\n",
      "Epoch [2/5], Loss: 0.0890\n",
      "Epoch [2/5], Loss: 0.0984\n",
      "Epoch [2/5], Loss: 0.0585\n",
      "Epoch [2/5], Loss: 0.0592\n",
      "Epoch [2/5], Loss: 0.0603\n",
      "Epoch [2/5], Loss: 0.0479\n",
      "Epoch [2/5], Loss: 0.0564\n",
      "Epoch [2/5], Loss: 0.0698\n",
      "Epoch [2/5], Loss: 0.0584\n",
      "Epoch [2/5], Loss: 0.0604\n",
      "Epoch [2/5], Loss: 0.0629\n",
      "Epoch [2/5], Loss: 0.0746\n",
      "Epoch [2/5], Loss: 0.0755\n",
      "Epoch [2/5], Loss: 0.1152\n",
      "Epoch [2/5], Loss: 0.0526\n",
      "Epoch [2/5], Loss: 0.1064\n",
      "Epoch [3/5], Loss: 0.0893\n",
      "Epoch [3/5], Loss: 0.0695\n",
      "Epoch [3/5], Loss: 0.0586\n",
      "Epoch [3/5], Loss: 0.0570\n",
      "Epoch [3/5], Loss: 0.0588\n",
      "Epoch [3/5], Loss: 0.0718\n",
      "Epoch [3/5], Loss: 0.0532\n",
      "Epoch [3/5], Loss: 0.0655\n",
      "Epoch [3/5], Loss: 0.0772\n",
      "Epoch [3/5], Loss: 0.0541\n",
      "Epoch [3/5], Loss: 0.0590\n",
      "Epoch [3/5], Loss: 0.0501\n",
      "Epoch [3/5], Loss: 0.0443\n",
      "Epoch [3/5], Loss: 0.0526\n",
      "Epoch [3/5], Loss: 0.0514\n",
      "Epoch [3/5], Loss: 0.0474\n",
      "Epoch [3/5], Loss: 0.0822\n",
      "Epoch [3/5], Loss: 0.0784\n",
      "Epoch [3/5], Loss: 0.0567\n",
      "Epoch [3/5], Loss: 0.0508\n",
      "Epoch [3/5], Loss: 0.0485\n",
      "Epoch [3/5], Loss: 0.0558\n",
      "Epoch [3/5], Loss: 0.0465\n",
      "Epoch [3/5], Loss: 0.0447\n",
      "Epoch [3/5], Loss: 0.0573\n",
      "Epoch [3/5], Loss: 0.0440\n",
      "Epoch [3/5], Loss: 0.0499\n",
      "Epoch [3/5], Loss: 0.0648\n",
      "Epoch [3/5], Loss: 0.0899\n",
      "Epoch [3/5], Loss: 0.0618\n",
      "Epoch [3/5], Loss: 0.0531\n",
      "Epoch [3/5], Loss: 0.1102\n",
      "Epoch [3/5], Loss: 0.0691\n",
      "Epoch [3/5], Loss: 0.0513\n",
      "Epoch [3/5], Loss: 0.0611\n",
      "Epoch [3/5], Loss: 0.0473\n",
      "Epoch [3/5], Loss: 0.0590\n",
      "Epoch [3/5], Loss: 0.0487\n",
      "Epoch [3/5], Loss: 0.0415\n",
      "Epoch [3/5], Loss: 0.0575\n",
      "Epoch [3/5], Loss: 0.0828\n",
      "Epoch [3/5], Loss: 0.0390\n",
      "Epoch [3/5], Loss: 0.0505\n",
      "Epoch [3/5], Loss: 0.0504\n",
      "Epoch [3/5], Loss: 0.0624\n",
      "Epoch [3/5], Loss: 0.0367\n",
      "Epoch [3/5], Loss: 0.0706\n",
      "Epoch [3/5], Loss: 0.0556\n",
      "Epoch [3/5], Loss: 0.0528\n",
      "Epoch [3/5], Loss: 0.0845\n",
      "Epoch [3/5], Loss: 0.0512\n",
      "Epoch [3/5], Loss: 0.0461\n",
      "Epoch [3/5], Loss: 0.0609\n",
      "Epoch [3/5], Loss: 0.0838\n",
      "Epoch [4/5], Loss: 0.0467\n",
      "Epoch [4/5], Loss: 0.0433\n",
      "Epoch [4/5], Loss: 0.0582\n",
      "Epoch [4/5], Loss: 0.0454\n",
      "Epoch [4/5], Loss: 0.0460\n",
      "Epoch [4/5], Loss: 0.0578\n",
      "Epoch [4/5], Loss: 0.0569\n",
      "Epoch [4/5], Loss: 0.0607\n",
      "Epoch [4/5], Loss: 0.0419\n",
      "Epoch [4/5], Loss: 0.0406\n",
      "Epoch [4/5], Loss: 0.0369\n",
      "Epoch [4/5], Loss: 0.0638\n",
      "Epoch [4/5], Loss: 0.0439\n",
      "Epoch [4/5], Loss: 0.0502\n",
      "Epoch [4/5], Loss: 0.0528\n",
      "Epoch [4/5], Loss: 0.0380\n",
      "Epoch [4/5], Loss: 0.0381\n",
      "Epoch [4/5], Loss: 0.0379\n",
      "Epoch [4/5], Loss: 0.0409\n",
      "Epoch [4/5], Loss: 0.0781\n",
      "Epoch [4/5], Loss: 0.0742\n",
      "Epoch [4/5], Loss: 0.0441\n",
      "Epoch [4/5], Loss: 0.0600\n",
      "Epoch [4/5], Loss: 0.0484\n",
      "Epoch [4/5], Loss: 0.0503\n",
      "Epoch [4/5], Loss: 0.0458\n",
      "Epoch [4/5], Loss: 0.0402\n",
      "Epoch [4/5], Loss: 0.0585\n",
      "Epoch [4/5], Loss: 0.0457\n",
      "Epoch [4/5], Loss: 0.0544\n",
      "Epoch [4/5], Loss: 0.0480\n",
      "Epoch [4/5], Loss: 0.0618\n",
      "Epoch [4/5], Loss: 0.0356\n",
      "Epoch [4/5], Loss: 0.0436\n",
      "Epoch [4/5], Loss: 0.0319\n",
      "Epoch [4/5], Loss: 0.0415\n",
      "Epoch [4/5], Loss: 0.0595\n",
      "Epoch [4/5], Loss: 0.0434\n",
      "Epoch [4/5], Loss: 0.0560\n",
      "Epoch [4/5], Loss: 0.0411\n",
      "Epoch [4/5], Loss: 0.1011\n",
      "Epoch [4/5], Loss: 0.0420\n",
      "Epoch [4/5], Loss: 0.0596\n",
      "Epoch [4/5], Loss: 0.0390\n",
      "Epoch [4/5], Loss: 0.0491\n",
      "Epoch [4/5], Loss: 0.0397\n",
      "Epoch [4/5], Loss: 0.0342\n",
      "Epoch [4/5], Loss: 0.0379\n",
      "Epoch [4/5], Loss: 0.0341\n",
      "Epoch [4/5], Loss: 0.0672\n",
      "Epoch [4/5], Loss: 0.0370\n",
      "Epoch [4/5], Loss: 0.0324\n",
      "Epoch [4/5], Loss: 0.0564\n",
      "Epoch [4/5], Loss: 0.1193\n",
      "Epoch [5/5], Loss: 0.0310\n",
      "Epoch [5/5], Loss: 0.0597\n",
      "Epoch [5/5], Loss: 0.0447\n",
      "Epoch [5/5], Loss: 0.0632\n",
      "Epoch [5/5], Loss: 0.0478\n",
      "Epoch [5/5], Loss: 0.0545\n",
      "Epoch [5/5], Loss: 0.0363\n",
      "Epoch [5/5], Loss: 0.0240\n",
      "Epoch [5/5], Loss: 0.0445\n",
      "Epoch [5/5], Loss: 0.0404\n",
      "Epoch [5/5], Loss: 0.0283\n",
      "Epoch [5/5], Loss: 0.0319\n",
      "Epoch [5/5], Loss: 0.0407\n",
      "Epoch [5/5], Loss: 0.0437\n",
      "Epoch [5/5], Loss: 0.0477\n",
      "Epoch [5/5], Loss: 0.0363\n",
      "Epoch [5/5], Loss: 0.0323\n",
      "Epoch [5/5], Loss: 0.0405\n",
      "Epoch [5/5], Loss: 0.0339\n",
      "Epoch [5/5], Loss: 0.0337\n",
      "Epoch [5/5], Loss: 0.0293\n",
      "Epoch [5/5], Loss: 0.0479\n",
      "Epoch [5/5], Loss: 0.0303\n",
      "Epoch [5/5], Loss: 0.0340\n",
      "Epoch [5/5], Loss: 0.0468\n",
      "Epoch [5/5], Loss: 0.0390\n",
      "Epoch [5/5], Loss: 0.0343\n",
      "Epoch [5/5], Loss: 0.0258\n",
      "Epoch [5/5], Loss: 0.0331\n",
      "Epoch [5/5], Loss: 0.0403\n",
      "Epoch [5/5], Loss: 0.0457\n",
      "Epoch [5/5], Loss: 0.0352\n",
      "Epoch [5/5], Loss: 0.0420\n",
      "Epoch [5/5], Loss: 0.0696\n",
      "Epoch [5/5], Loss: 0.0360\n",
      "Epoch [5/5], Loss: 0.0336\n",
      "Epoch [5/5], Loss: 0.0289\n",
      "Epoch [5/5], Loss: 0.0349\n",
      "Epoch [5/5], Loss: 0.0323\n",
      "Epoch [5/5], Loss: 0.1019\n",
      "Epoch [5/5], Loss: 0.0363\n",
      "Epoch [5/5], Loss: 0.0313\n",
      "Epoch [5/5], Loss: 0.0390\n",
      "Epoch [5/5], Loss: 0.0582\n",
      "Epoch [5/5], Loss: 0.0470\n",
      "Epoch [5/5], Loss: 0.0470\n",
      "Epoch [5/5], Loss: 0.0450\n",
      "Epoch [5/5], Loss: 0.0320\n",
      "Epoch [5/5], Loss: 0.0421\n",
      "Epoch [5/5], Loss: 0.0275\n",
      "Epoch [5/5], Loss: 0.0399\n",
      "Epoch [5/5], Loss: 0.0334\n",
      "Epoch [5/5], Loss: 0.0367\n",
      "Epoch [5/5], Loss: 0.0704\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "train_model(5, model, train_loader, device)  # Train for 10 epochs\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'captcha_resnet18.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captcha-reading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
